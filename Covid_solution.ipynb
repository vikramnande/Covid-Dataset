{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid_solution(16ME31005).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dziKHhUZhCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import cv2\n",
        "\n",
        "from PIL import Image\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2T6gaW17gk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/ieee8023/covid-chestxray-dataset.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qcJqmBd6th7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = '/content/covid-chestxray-dataset/metadata.csv'\n",
        "imagepath = '/content/covid-chestxray-dataset/images/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvhJhgmV63Cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(filepath)\n",
        "print(df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zGMbxV368Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDd0YlTm9aWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = df['finding'].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pORVbTA-_BN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR9xPOsv8kO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "positive_images = []#positive images\n",
        "filename = []\n",
        "for(i,row) in df.iterrows():\n",
        "  if row[\"finding\"] == \"COVID-19\" and row[\"view\"]==\"PA\":\n",
        "    filename.append(row[\"filename\"])\n",
        "    # print(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-fMm_m1sVFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for f in filename:\n",
        "  positive_images.append(imagepath+f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wyN2D1m_Yc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u50hTl5pLzYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import random "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdJVY-2pRsrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_normal = '/content/drive/My Drive/normal'\n",
        "normal_images = os.listdir(path_normal)\n",
        "random.shuffle(normal_images)\n",
        "norml_images  = []#normal images\n",
        "for i in range(len(positive_images)):\n",
        "  norml_images.append(path_normal+'/'+normal_images[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dexqtzs0uy9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norml_images[76]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fug0j2qK8EGi",
        "colab_type": "text"
      },
      "source": [
        "We are considering equal number of positive and negative cases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZOyjSzkTXAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = []#saving labels in a list\n",
        "leng = 2*len(positive_images)\n",
        "for i in range(leng):\n",
        "  label.append(1)\n",
        "\n",
        "for i in range(int(leng/2)):\n",
        "  label[i+int(leng/2)] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeNt9JQ1Q-pR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagepaths = []#appending paths of all images\n",
        "for imag in positive_images:\n",
        "  imagepaths.append(imag)\n",
        "\n",
        "for imag in norml_images:\n",
        "  imagepaths.append(imag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY8myedvWKxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = {1:'Corona',0:'Normal'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwMDgynuMw7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "pretrained_size = 224\n",
        "train_transforms = transforms.Compose([\n",
        "                           transforms.Resize(pretrained_size),\n",
        "                           transforms.RandomResizedCrop(224),\n",
        "                           transforms.ToTensor()\n",
        "                       ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VGvSV1PLSwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class newdataset(Dataset):\n",
        "  \n",
        "  def __init__(self,imagepaths,labels,transform=None):\n",
        "    self.imagelist = imagepaths\n",
        "    self.label = labels\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imagelist)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    image_path = self.imagelist[index]\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img = self.transform(img)\n",
        "    lab = self.label[index]\n",
        "\n",
        "    return img,lab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRXLfmvbLv3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = newdataset(imagepaths,label,transform=train_transforms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvfQ2yaI2ctz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ratio = 0.8\n",
        "n_train_examples = int(len(dataset) * ratio)\n",
        "n_valid_examples = len(dataset) - n_train_examples\n",
        "\n",
        "train,test = torch.utils.data.random_split(dataset, [n_train_examples, n_valid_examples])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQsVnah731Vi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_ratio = 0.5\n",
        "val_examples = int(len(test)*val_ratio)\n",
        "test_examples = len(test)-val_examples\n",
        "\n",
        "val,final_test = torch.utils.data.random_split(test,[val_examples,test_examples])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu8ON_1xoJz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "train_loader = torch.utils.data.DataLoader(train,shuffle = True, batch_size = BATCH_SIZE)\n",
        "val_loader = torch.utils.data.DataLoader(val,shuffle = True, batch_size = BATCH_SIZE)\n",
        "test_loader = torch.utils.data.DataLoader(test,shuffle = True, batch_size = BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvDf4xBASTUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Xraynet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Xraynet,self).__init__()\n",
        "\n",
        "    self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1,bias=True)\n",
        "    self.conv2 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, bias=True)\n",
        "    self.max_pool_1 = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "    self.conv3 = torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, bias=True)\n",
        "    self.max_pool_2 = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "    self.conv4 = torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, bias=True)\n",
        "    self.max_pool_3 = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "    self.conv5 = torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, bias=True)\n",
        "    self.max_pool_4 = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=18432, out_features=4000)   #Flattened image is fed into linear NN and reduced to half size\n",
        "    self.droput = nn.Dropout(p=0.5)                    #Dropout used to reduce overfitting\n",
        "    self.fc2 = nn.Linear(in_features=4000, out_features=2000)\n",
        "    self.droput = nn.Dropout(p=0.5)\n",
        "    self.fc3 = nn.Linear(in_features=2000, out_features=500)\n",
        "    self.droput = nn.Dropout(p=0.5)\n",
        "    self.fc4 = nn.Linear(in_features=500, out_features=50)\n",
        "    self.droput = nn.Dropout(p=0.5)\n",
        "    self.fc5 = nn.Linear(in_features=50, out_features=2)     \n",
        "    self.relu = nn.ReLU() \n",
        "\n",
        "    self.dropout_1 = torch.nn.Dropout(0.25)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = torch.nn.functional.relu(self.conv1(x))\n",
        "    x = torch.nn.functional.relu(self.conv2(x))\n",
        "    x = self.max_pool_1(x)\n",
        "    x = self.dropout_1(x)\n",
        "\n",
        "    x = torch.nn.functional.relu(self.conv3(x))\n",
        "    x = self.max_pool_2(x)\n",
        "    x = self.dropout_1(x)\n",
        "\n",
        "    x = torch.nn.functional.relu(self.conv4(x))\n",
        "    x = self.max_pool_3(x)\n",
        "    x = self.dropout_1(x)\n",
        "\n",
        "    x = torch.nn.functional.relu(self.conv5(x))\n",
        "    x = self.max_pool_4(x)\n",
        "    x = self.dropout_1(x)\n",
        "\n",
        "    x = x.view(-1,18432)\n",
        "    out = self.fc1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.droput(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.droput(out)\n",
        "    out = self.fc3(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.droput(out)\n",
        "    out = self.fc4(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.droput(out)\n",
        "    out = self.fc5(out)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SANHRvz_P-CU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff6Casz4dQSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Xraynet()\n",
        "# defining the optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=2e-4,betas=(0.9, 0.99),weight_decay=0.0005)\n",
        "# defining the loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# checking if GPU is available\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0xrlMhVsPIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQQ9tkSh68IX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainmodel(epoch):\n",
        "  \n",
        "  model.train()\n",
        "  for i in range(epoch):\n",
        "    \n",
        "    tr_loss = 0\n",
        "    best_loss = 0\n",
        "    best_loss = 9999\n",
        "    optimizer.zero_grad()\n",
        "    for x,target in train_loader:\n",
        "      x, target = Variable(x), Variable(target)\n",
        "      \n",
        "      output_train = model(x.float().cuda())\n",
        "      _, preds = torch.max(output_train.data, 1)\n",
        "      target = target.to('cpu')\n",
        "      preds = preds.to('cpu')\n",
        "      \n",
        "      print(preds==target.data)\n",
        "      \n",
        "      loss_train = criterion(output_train,target.cuda())\n",
        "      train_losses.append(loss_train)\n",
        "      loss_train.backward()\n",
        "      optimizer.step()\n",
        "      tr_loss = loss_train.item()\n",
        "      \n",
        "    with torch.no_grad():\n",
        "      running_loss = 0\n",
        "      for val,val_target in val_loader:\n",
        "        \n",
        "        val,val_target = Variable(val), Variable(val_target)\n",
        "        output_val = model(val.float().cuda())\n",
        "        \n",
        "        loss_val = criterion(output_val, val_target.cuda())\n",
        "        running_loss += loss_val.item()\n",
        "        \n",
        "        if(loss_val.item()<best_loss):\n",
        "          best_loss = loss_val\n",
        "          bestweights = model.state_dict()\n",
        "\n",
        "        val_losses.append(loss_val)\n",
        "        \n",
        "      print('Epoch : ',i+1, '\\t', 'loss :', running_loss/len(val))\n",
        "\n",
        "  model.load_state_dict(bestweights) \n",
        "  return model   \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bpf3i_QllyOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 25\n",
        "# empty list to store training losses\n",
        "train_losses = []\n",
        "# empty list to store validation losses\n",
        "val_losses = []\n",
        "# training the model\n",
        "Model = trainmodel(n_epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JS4j9EOmDbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "running_corrects = 0\n",
        "for img,out in test_loader:\n",
        "  img,out = Variable(img), Variable(out)\n",
        "  output_val = Model(img.float().cuda())\n",
        "  _, preds = torch.max(output_val.data, 1)\n",
        "  \n",
        "  out = out.to('cpu')\n",
        "  preds = preds.to('cpu')\n",
        "  running_corrects += torch.sum(preds == out.data).item()\n",
        "\n",
        "test_Accuracy = running_corrects/len(test)\n",
        "print(test_Accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}